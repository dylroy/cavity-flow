{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8f435b",
   "metadata": {},
   "source": [
    "# Building a framework for exploratory Geophysical Fluid Dynamics: A test-case with Lid-Driven Cavity Flows\n",
    "### Spring 2025, created by: Dylan Joseph Roy-Leo\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. Introduction: Motivation & Background\n",
    "2. Governing Equations & Numerical Methods\n",
    "3. Python Implementation\n",
    "    - Initialization\n",
    "    - Boundary Conditions\n",
    "    - Solver Functions\n",
    "    - Time Integration\n",
    "4. Results & Visualization\n",
    "5. Data Analysis & Discussion\n",
    "6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad90fa",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e627a",
   "metadata": {},
   "source": [
    "#### Interest in GFD\n",
    "\n",
    "Salt marshes are incredibly important ecosystems for many coastal communities around the world. Among the many services that they provide, the one of relevance to me is their ability to buffer shorelines against relative sea level rise (RSLR) and prevent the erosion of coastal sedimentary cliffs. However, salt marshes require a yearly sediment budget, potentially transported through the marshes connection with the sea as sediment is carried in with the tide, or potentially transported via rivers that connect to the marsh and periodically dump massive amounts of sediment directly onto the marsh platform after large storm events. As for the first avenue of sediment transport, the open ocean, there are limited sources to where that sediment can come from. Either, the sediment came originally from a river and travelled to the open ocean where coastal currents carried it back into a marsh, the sediment was resuspended from the ocean shelf by a large storm, or the sediment was directly eroded from the land (most likely by a large storm event) and transported to the marsh via coastal currents. The easiest of those three possibilities to probe, and the topic of my Master's thesis, is the last. I'm interested in how sediment eroded from coastal landforms called bluffs is transported from the site of erosion by coastal currents, and my big question is \"how much of the sediment eroded from bluffs gets deposited on the marsh surface?\".\n",
    "\n",
    "The first part of my Master's thesis was focused on quantifying the volume and mass of fine-grain sediment eroded from the coast via combining LiDAR differencing with Surficial Geology data. The results from that work proved to be interesting, but not satisfying. I was able to show that bluff erosion supplied more than enough sediment between 2011 and 2021 in Massachusetts to the coastal zone than what all marshes in Massachusetts would require within that same time frame. This is not what we expected, and shows that bluff erosion may be a significant contributor in marsh sustenance.\n",
    "\n",
    "However, there is a problem. For none of the eroded sediment that I was able to document, *none of it*, was I able to say made it way to a marsh platform. Let alone deposited and contributed to its accretion. Once sediment is eroded from the coast, its a black box, with the methods I had at my diposal I was not able to say that even a single kilogram made its way to a marsh. And in fact, in some areas where eroded bluff were further downstream in a littoral cell from a marsh, you could pretty confidently say that the sediment from particular bluff would *never* make it to a particular marsh. To me, this highlighted the pressing need to find a method that would allow you to make predictions about the incredibly complex nature of coastal currents, and the sediment suspended therein.\n",
    "\n",
    "With that said salt marshes are inherently dynamical systems. Their very nature is tied, at the very least, to the daily cycle of tides which pushes massives amounts of fluid onto the marsh surface. This water interacts in complex and mostly unknown ways with topology of the marsh and with the vegetation on the marsh. The mechanics of how coastal waters flow over the marsh surface, and how that flow impacts marsh characteristics such as sediment delivery, is an incredibly complex topic. Three-dimensional fluid mechanic models such as the Finite Volume Community Ocean Model (FVCOM) are as close as we have to understanding the meso-scale dynamics of marsh ecosystems. These models have given us valuable insights into how salinity, temperature, and suspended sediment are transported in a marsh.\n",
    "\n",
    "Enter Geophysical Fluid Dynamics. One of the more fascinating and tempting subjects I've encountered in a long time, GFD is the study and pursuit of modelling the fluid dynamics of planet earth. This can include atmospheric GFD where weather patterns and atmospheric circulations are studied, and it can also include physical oceanography were ocean currents at both large and small scale are studied. There are other brands of fluid dynamics as well, including Computational Fluid Dynamics, and in many ways they all feed into one another. GFD is particularly interesting to me not just becuase it might allow me an avenue to answer my Thesis questions, but also becuase I've come to recognize the particular strength that GFD holds within the realm of fluid dynamics. And that strength is its vast complexity. Geophysical systems are noisy, irregular, and can have upwards of infinite degrees of freedom, and these facts can make it incredibly difficult to model geophysical systems. However, in the same token, GFD is incredibly rich and has a vast wealth of untapped potential. In combination with advances in both the field of data driven science and engineering as well as remote sensing, I believe GFD has more to offer than ever, highlighting my fervent interest in diving head-first into this subject.\n",
    "\n",
    "#### Motivations for this project\n",
    "As I've spent around the past year or so diving into GFD, one thing that always irked me was my inability to model the systems I was learning about. I assumed that as I became more familiar with the theoretical foundation of solving the PDEs required to model fluid flow, and as I became more competent in the algorithmic methods used to translate continuous mathematics to discrete machines, that I would slowly be able to model more and more systems, finally giving me the hands-on experience I was craving from this field. This . . . sort of, came to pass. Watching YouTube tutorials online its pretty easy to boot up Python or Matlab and follow the guide step-by-step to get a working model of some rudimentary system. However, as I came to find, this had limited applicability when it came to hands-on learning. The reason for that is that when I built these models, I wanted to mess with everything, all the parameters, all the modules, all the configurations. But fluid dynamics models are usually built exactly for the problem at hand, and there is so much intricacy in the boundary conditions, the initial conditions, the choice of numerical solver, how the numerical solver and the boundary conditions interact, and the time stepping scheme, among many, many others.\n",
    "\n",
    "My goal for this project initially was to develop a framework for building toy dynamical systems models. The result, I was hoping, was for a fairly straighforward and educational way to piece together different aspects of fluid dynamics simulations like Lego bricks. Besides simple things like changing the time step, I wanted to know what would be the result of changing the integrator from a Runge-Kutta fourth order scheme to a Runge-Kutta second order scheme? If I solve the PDE in Fourier coordinates and inverse transform back (spectral methods), how does that compare to locally calculating derivatives and solving that way (finite-difference)?\n",
    "\n",
    "I went at this project that this would be the start to a life-long personal project, which perhaps was the wrong way to go about it, as scope-creep and perfectionism became a real hurdle to jump over. In the end though, what I decided was that for this project in particular, this was to be a test-case for my vision. I decided to use the Lid-Driven Cavity Flow simulation as the prototype for what a GFD simulation framework might look like in the future, I'll describe my reasons for this simulation in particular below.\n",
    "\n",
    "#### Lid-Driven Cavity Flow\n",
    "As stated above, GFD simulations can be very difficult to set up, especially without the priviledge of a background in engineering or applied mathematics. The Lid-Driven Cavity Flow was chosen as a test-case for this project for the reason that its fairly simple, it can be implemented on a uniform and structured mesh (reducing complexity), it models fluid dynamics using the Navier-Stokes equations (benchmark of fluid dynamics), it can display complex and interesting behavior, and it's directly applicable to some of the dynamics observed in natural systems (natural cavities like back-barrier marshes).\n",
    "\n",
    "The concept behind the Lid-Driven Cavity Flow is fairly straightforward, there is a box filled with fluid with one side of the box open (typically the top, hence the name *Lid*-Driven). Along that open side, we imagine that there is a constant stream of fluid interacting with that side (outside of the domain), causing the fluid along that side to be consistently pushed in one direction (typically to the right). After we set up the domain, we *prescribe* a constant velocity to the cells along the top of the box, and the rest of the simulation is calculating the resulting dynamics of the rest of the fluid within the box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca31ee",
   "metadata": {},
   "source": [
    "## 2. Governing Equations and Numerical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8e2a4",
   "metadata": {},
   "source": [
    "As mentioned in the introduction, the Lid-Driven Cavity Flow model is \"powered\" by the Navier-Stokes system of equations. Let's break them down below:\n",
    "\n",
    "First equation (momentum equation): $\\frac{\\partial U}{\\partial t} + U \\cdot \\nabla U = -\\frac{1}{\\rho}\\nabla p + \\nu \\nabla^2U$\n",
    "\n",
    "Second equation (continuity equation): $\\nabla \\cdot U = 0$\n",
    "\n",
    "The momentum equation is an expansion of $F=ma$ from Newtonian mechanics, whereas the continuity equation enforces the simplification that the fluid is incompressible. $\\nabla \\cdot U$ is the divergence of the vector field $u$ and can also be written as $(\\frac{\\partial u}{\\partial x} + \\frac{\\partial w}{\\partial y})$ (the use of $U$ vs $u$ is to highlight that $U$ is the whole vector field, and u is the scalar field representing the x-component of the velocity of $U$, whereas $w$ is the y-component.)\n",
    "\n",
    "In this notebook, the scheme to solving the Navier-Stokes equation is broken up into two steps. First, the momentum equation is rearranged and the pressure term is removed (for now):  \n",
    "  \n",
    "$\\frac{\\partial U}{\\partial t} = -U \\cdot \\nabla U + \\nu \\nabla^2U$  \n",
    "  \n",
    "This equation is solved using finite-difference techniques and what is calculated are the *tentative velocities* $U^{*}(u^{*},w^{*})$. This step advects the fluid forward in time based on their current velocities to where they would be if there was no pressure gradient or incompressibility condition.\n",
    "\n",
    "The second step involves solving a Pressure Poisson equation to calculate the correction to the tentative velocities, and then applying them.  \n",
    "  \n",
    "$\\Delta p = -\\rho \\nabla \\cdot (U \\cdot \\nabla U)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dbd30a",
   "metadata": {},
   "source": [
    "## 3. Python Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee75cca",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc29207",
   "metadata": {},
   "source": [
    "The packages used in this notebook are `numpy` for vecorized computation and handling of gridded data, `xarray` for storage of gridded data with coordinates and attributes, and `matplotlib` and `holoviews` for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d129b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.7.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.7.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.holoviz.org/panel/1.7.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='8012f18a-a060-4820-8876-6c51295ce840'>\n",
       "  <div id=\"f6e07d02-754f-4370-8131-9a9c5a6350fa\" data-root-id=\"8012f18a-a060-4820-8876-6c51295ce840\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"05ddaa92-1253-455a-96f3-679b7f432e0c\":{\"version\":\"3.7.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"8012f18a-a060-4820-8876-6c51295ce840\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"c6c15c06-f8b3-47ac-96e8-1100d7022db5\",\"attributes\":{\"plot_id\":\"8012f18a-a060-4820-8876-6c51295ce840\",\"comm_id\":\"730fb7ac8af440a0b6fd6b520afdfe5f\",\"client_comm_id\":\"e29ed5521cf44618a8acf9d68386e35f\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"05ddaa92-1253-455a-96f3-679b7f432e0c\",\"roots\":{\"8012f18a-a060-4820-8876-6c51295ce840\":\"f6e07d02-754f-4370-8131-9a9c5a6350fa\"},\"root_ids\":[\"8012f18a-a060-4820-8876-6c51295ce840\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "8012f18a-a060-4820-8876-6c51295ce840"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACMAAAAjCAYAAAAe2bNZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAK6wAACusBgosNWgAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAf9SURBVFiFvZh7cFTVHcc/59y7793sJiFAwkvAYDRqFWwdraLVlj61diRYsDjqCFbFKrYo0CltlSq1tLaC2GprGIriGwqjFu10OlrGv8RiK/IICYECSWBDkt3s695zTv9IAtlHeOn0O7Mzu797z+/3Ob/z+p0VfBq9doNFljuABwAXw2PcvGHt6bgwxhz7Ls4YZNVXxxANLENwE2D1W9PAGmAhszZ0/X9gll5yCbHoOirLzmaQs0F6F8QMZq1v/8xgNm7DYwwjgXJLYL4witQ16+sv/U9HdDmV4WrKw6B06cZC/RMrM4MZ7xz61DAbtzEXmAvUAX4pMOVecg9/MFFu3j3Gz7gQBLygS2RGumBkL0cubiFRsR3LzVBV1UMk3IrW73PT9C2lYOwhQB4ClhX1AuKpjLcV27oEjyUpNUJCg1CvcejykWTCXyQgzic2HIIBjg3pS6+uRLKAhumZvD4U+tq0jTrgkVKQQtLekfTtxIPAkhTNF6G7kZm7aPp6M9myKVQEoaYaIhEQYvD781DML/RfBGNZXAl4irJiwBa07e/y7cQnBaJghIX6ENl2GR/fGCBoz6cm5qeyEqQA5ZYA5x5eeiV0Qph4gjFAUSwAr6QllQgcxS/Jm25Cr2Tmpsk03XI9NfI31FTZBEOgVOk51adqDBNPCNPSRlkiDXbBEwOU2WxH+I7itQZ62g56OjM33suq1YsZHVtGZSUI2QdyYgkgOthQNIF7BIGDnRAJgJSgj69cUx1gB8PkOGwL4E1gPrM27gIg7NlGKLQApc7BmEnAxP5g/rw4YqBrCDB5xHkw5rdR/1qTrN/hKNo6YUwVDNpFsnjYS8RbidBPcPXFP6R6yfExuOXmN4A3jv1+8ZUwgY9D2OWjUZE6lO88jDwHI8ZixGiMKSeYTBamCoDk6kDAb6y1OcH1a6KpD/fZesoFw5FlIXAVCIiH4PxrV+p2npVDToTBmtjY8t1swh2V61E9KqWiyuPEjM8dbfxuvfa49Zayf9R136Wr8mBSf/T7bNteA8zwaGEUbFpckWwq95n59dUIywKl2fbOIS5e8bWSu0tJ1a5redAYfqkdjesodFajcgaVNWhXo1C9SrkN3Usmv3UMJrc6/DDwkwEntkEJLe67tSLhvyzK8rHDQWleve5CGk4VZEB1r+5bg2E2si+Y0QatDK6jUVkX5eg2YYlp++ZM+rfMNYamAj8Y7MAVWFqaR1f/t2xzU4IHjybBtthzuiAASqv7jTF7jOqDMAakFHgDNsFyP+FhwZHBmH9F7cutIYkQCylYYv1AZSqsn1/+bX51OMMjPSl2nAnM7hnjOx2v53YgNWAzHM9Q/9l0lQWPSCBSyokAtOBC1Rj+w/1Xs+STDp4/E5g7Rs2zm2+oeVd7PUuHKDf6A4r5EsPT5K3gfCnBXNUYnvGzb+KcCczYYWOnLpy4eOXuG2oec0PBN8XQQAnpvS35AvAykr56rWhPBiV4MvtceGLxk5Mr6A1O8IfK7rl7xJ0r9kyumuP4fa0lMqTBLJIAJqEf1J3qE92lMBndlyfRD2YBghHC4hlny7ASqCeWo5zaoDdIWfnIefNGTb9fC73QDfhyBUCNOxrGPSUBfPem9us253YTV+3mcBbdkUYfzmHiLqZbYdIGHHON2ZlemXouaJUOO6TqtdHEQuXYY8Yt+EbDgmlS6RdzkaDTv2P9A3gICiq93sWhb5mc5wVhuU3Y7m5hOc3So7qFT3SLgOXHb/cyOfMn7xROegoC/PTcn3v8gbKPgDopJFk3R/uBPWQiwQ+2/GJevRMObLUzqe/saJjQUQTTftEVMW9tWxPgAocwcj9abNcZe7s+6t2R2xXZG7zyYLp8Q1PiRBBHym5bYuXi8Qt+/LvGu9f/5YDAxABsaRNPH6Xr4D4Sk87a897SOy9v/fKwjoF2eQel95yDESGEF6gEMwKhLwKus3wOVjTtes7qzgLdXTMnNCNoEpbcrtNuq6N7Xh/+eqcbj94xQkp7mdKpW5XbtbR8Z26kgMCAf2UU5YEovRUVRHbu2b3vK1UdDFkDCyMRQxbpdv8nhKAGIa7QaQedzT07fFPny53R738JoVYBdVrnsNx9XZ9v33UeGO+AA2MMUkgqQ5UcdDLZSFeVgONnXeHqSAC5Ew1BXwko0D1Zct3dT1duOjS3MzZnEUJtBuoQAq3SGOLR4ekjn9NC5nVOaYXf9lETrUkmOJy3pOz8OKIb2A1cWhJCCEzOxU2mUPror+2/L3yyM3pkM7jTjr1nBOgkGeyQ7erxpdJsMAS9wb2F9rzMxNY1K2PMU0WtZV82VU8Wp6vbKJVo9Lx/+4cydORdxCCQ/kDGTZCWsRpLu7VD7bfKqL8V2orKTp/PtzaXy42jr6TwAuisi+7JolUG4wY+8vyrISCMtRrLKWpvjAOqx/QGhp0rjRo5xD3x98CWQuOQN8qumRMmI7jKZPUEpzNVZsj4Zbaq1to5tZZsKIydLWojhIXrJnES79EaOzv3du2NytKuxzJKAA6wF8xqEE8s2jo/1wd/khslQGxd81Zg62Bbp31XBH+iETt7Y3ELA0iU6iGDlQ5mexe0VEx4a3x8V1AaYwFJgTiwaOsDmeK2J8nMUOqsnB1A+dcA04ucCYt0urkjmflk9iT2v30q/gZn5rQPvor4n9Ou634PeBzoznes/iot/7WnClKoM/+zCIjH5kwT8ChQjTHPIPTjFV3PpU/Hx+DM/A9U3IXI4SPCYAAAAABJRU5ErkJggg=='\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "hv.extension('bokeh')\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf39b740",
   "metadata": {},
   "source": [
    "Step one to initialization is to define the initial conditions for the three model variables in this project: $u$, the x component of velocity; $w$, the y component of velocity; and $p$, the pressure. The initial condition for each of these variables is defined across each dimension of computational mesh, and is later summed together, allowing for complex initial conditions to be tested. For this example, functions should simply be set to `lambda x: x*0`, which will set the initial conditions for each variable and across each dimension to zero. In plain english, this means that at the beginning of the simulation, the fluid is perfectly still with no pressure gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5bf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufunc_x = lambda x: x*0\n",
    "ufunc_y = lambda y: y*0\n",
    "wfunc_x = lambda x: x*0\n",
    "wfunc_y = lambda y: y*0\n",
    "pfunc_x = lambda x: x*0\n",
    "pfunc_y = lambda y: y*0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55d67b",
   "metadata": {},
   "source": [
    "Below is listed a definition for all of the parameters and some notes about the default values:\n",
    "- `model_type`: \n",
    "In this implementation, `'navier_stokes'` is the only option. In future implementations, simulation configurations will be stored as instances of a `Config` class, with specific `model_type` string signature controlling the behavior of the `__init__` dunder method, allowing for cleaner code. However here, it is only a placeholder and does not change behavior.\n",
    "\n",
    "- `coords`: \n",
    "This parameters defines the coordinates of the grid in space and in time. Creating this variable as a dictionary is convenient, as it is the exact format used in XArray's DataArray `coord=` argument, which is used to store the datacube generated by the simulation.\n",
    "\n",
    "- `domain_size`:\n",
    "The number of discrete grid points along both the x- and y- directions. For simplicity, this implementation does not support irregular grids.\n",
    "\n",
    "- `dt`:\n",
    "This is the time step. Not recommended to change as Courant-Friedrichs-Lewy condition for stability could be violated. Of course, in an exploratory framework, this is encouraged, but the recommended settings will produce actual results.\n",
    "\n",
    "- `Ndt`:\n",
    "The number of discrete time points. This can be changed pretty freely, taking into consideration that very large values will result in longer computational times.\n",
    "\n",
    "- `ics`:\n",
    "ics stands for *I*nitial *C*ondition*S*, and should be set as a tuple of tuples, the inset tuples represent each variable for which an initial condition should be set ($u$,$w$,$p$), and the values within should hold the lambda functions which will map those values across each dimension (x, then y, in order).\n",
    "\n",
    "- `bcs`:\n",
    "bcs stands for *B*oundary *C*ondition*S*, and should be set as a tuple of tuples, similar to the initial conditions. This time, instead of the inset tuples representing each variable, they will represent the four sides of the computational mesh with the values representing the velocity to be set ($u$, then $w$, in order). The boundary condition for $p$ is omitted here and is instead hard-coded into the algorithm. This is becuase the pressure boundary condition is more complicated (homogeneous Neumann), reliant on the pressure from the previous time step, and is more difficult to implement within this current implementation of the framework.\n",
    "\n",
    "- `Kviscosity`:\n",
    "This is the kinematic viscosity of the fluid. This value should be changed with caution as it can cause the CFL condition to be violated at very small values. Higher values essentially indicates a \"stickier\" fluid.\n",
    "\n",
    "- `forcings`:\n",
    "A placeholder in this implementation. In future implementations, users will be allowed to specify where and when a force is to be added to any given cell by creating a space-time cube dataset of the specific force values.\n",
    "\n",
    "- `density`:\n",
    "The density of the fluid. This should remain at 1.\n",
    "\n",
    "- `poisson_iterations`:\n",
    "The number of iterations that the pressure poisson solver will iterate through, more interations will allow the solver to converge closer to the true solution, preventing error from propogating.\n",
    "\n",
    "- `CFL_condition`:\n",
    "The value that the Courant-Friedrichs-Lewy condition for stability will be checked against after each time integration, for explicit schemes this is typically set to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e4bfd",
   "metadata": {},
   "source": [
    "The parameters are commented out here becuase they will be initialized later in the notebook, where it is easier to scroll back and change things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0aa6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'navier_stokes'\n",
    "# domain_size = 1\n",
    "# Nx = 64\n",
    "# dt = 0.001\n",
    "# Ndt = 10\n",
    "# ics = ((ufunc_x,ufunc_y),(wfunc_x,wfunc_y),(pfunc_x,pfunc_y))\n",
    "# bcs = ((0,0),(0,0),(1,0),(0,0))\n",
    "# Kviscosity = 0.1\n",
    "# forcings = None\n",
    "# density = 1.0\n",
    "# poisson_iterations = 50\n",
    "# CFL_condition = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_t0(initial_conditions, by_dimension, *args):\n",
    "    \"\"\"\n",
    "    initial_conditions = tuple of tuples of form ((u_icx,uicy),(w_icx,w_icy),(p_icx,p_icy))\n",
    "    by_dimensions = bool, if True, lambda functions in `initial_conditions` is applied by dimension\n",
    "    *args = the coordinate arrays `X` and `Y` created from np.meshgrid()\n",
    "    \"\"\"\n",
    "    \n",
    "    if by_dimension is True:\n",
    "        variables_initcond = []\n",
    "\n",
    "        for variable in initial_conditions:\n",
    "            dim_counter = 0\n",
    "            intermediate = np.zeros_like(args[0])\n",
    "\n",
    "            for dimension in args:\n",
    "                intermediate += variable[dim_counter](dimension)\n",
    "                dim_counter += 1\n",
    "            variables_initcond.append(intermediate)\n",
    "    \n",
    "    elif by_dimension is False:\n",
    "        variables_initcond = [initial_conditions[0](np.zeros_like(args[0])) for _ in initial_conditions]\n",
    "    \n",
    "    return variables_initcond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762db852",
   "metadata": {},
   "source": [
    "Next we will create the function that is responsible for initializing our coordinate arrays, applying intial conditions from the lambda functions described above(propogating the initial conditions across the grid seperately for each dimension), and initializing the XArray DataArray object to store data. This function will allow us to build three XArray DataArray objects, each representing the computational mesh at each $\\Delta t$ for one of the three dependent variables in the simulation; the x-velocity component $u$, the y-velocity component $w$, and the pressure $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0cad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arrays(coords, ics, bcs):\n",
    "    \"\"\"\n",
    "    Takes in coords, ics, bcs\n",
    "    \"\"\"\n",
    "    X, Y = np.meshgrid(coords['xdim'], coords['ydim'], copy=True)\n",
    "    # a copy is made here becuase the original 1D coordinate arrays shouldn't have the \n",
    "    # potential to be modified\n",
    "    shape = tuple(coords[key].shape[0] for key in coords.keys())\n",
    "    dims = list([key for key in coords.keys()])\n",
    "\n",
    "    uxarr = xr.DataArray(np.zeros(shape),dims=dims,coords=coords)\n",
    "    wxarr = xr.DataArray(np.zeros(shape),dims=dims,coords=coords)\n",
    "    pxarr = xr.DataArray(np.zeros(shape),dims=dims,coords=coords)\n",
    "\n",
    "    # Enforce initial conditions\n",
    "    u_t_0, w_t_0, p_t_0 = initialize_t0(ics,True, X, Y)\n",
    "\n",
    "    uxarr.data[:,:,0] = u_t_0\n",
    "    wxarr.data[:,:,0] = w_t_0\n",
    "    pxarr.data[:,:,0] = p_t_0\n",
    "    # Enforce boundary conditions\n",
    "    # uxarr[:,:,0], wxarr[:,:,0] = enforce_bc(bcs, uxarr[:,:,0].data, wxarr[:,:,0].data)\n",
    "\n",
    "    return uxarr, wxarr, pxarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd66b7",
   "metadata": {},
   "source": [
    "### Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f7889",
   "metadata": {},
   "source": [
    "Now we need a method to apply the boundary conditions. As stated in the project goals, this notebook should be a framework for how modular GFD simulation can be improved upon in the future, and in that spirit, the `apply_boundary_conditions` function is created, which can be called to initialize, or can be called in the context of a time-stepping loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b92970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_bc(conditions, u, w):\n",
    "    \"\"\"\n",
    "    Takes in a tuple of tuples (`conditions`) in the form ((left_u, left_w), (right_u, right_w), (top_u, top_w), (bottom_u, bottom_w))\n",
    "    representing the assigned x and y velocity components for each boundary.\n",
    "\n",
    "    Also takes in additional arguements which are the scalar or vector field upon which we will be assigning boundary conditions\n",
    "    to, these will be `u` and `w`.\n",
    "\n",
    "    Returns a list of vector fields which can be unpacked via direct assignment.\n",
    "    \"\"\"\n",
    "\n",
    "    left_U, right_U, top_U, bottom_U = conditions # unpack boundary conditions for improved readability\n",
    "\n",
    "    u_new = u.copy()\n",
    "    w_new = w.copy()\n",
    "    \n",
    "    # bottom boundary conditions\n",
    "    u_new[-1,:] = bottom_U[0]\n",
    "    # left boundary conditions\n",
    "    u_new[:,0] = left_U[0]\n",
    "    # right boundary conditions\n",
    "    u_new[:,-1] = right_U[0]\n",
    "    # top boundary conditions\n",
    "    u_new[0,:] = top_U[0]\n",
    "    \n",
    "    # bottom boundary conditions\n",
    "    w_new[-1,:] = bottom_U[1]\n",
    "    # left boundary conditions\n",
    "    w_new[:,0] = left_U[1]\n",
    "    # right boundary conditions\n",
    "    w_new[:,-1] = right_U[1]\n",
    "    # top boundary conditions\n",
    "    w_new[0,:] = top_U[1]\n",
    "\n",
    "    return u_new, w_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b0012",
   "metadata": {},
   "source": [
    "### Solver Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd37bbb",
   "metadata": {},
   "source": [
    "The following cell defines the functions required to perform a central difference derivative in the x- and y- dimensions. These will be used to calculate $\\frac{\\partial u}{\\partial x}$ and $\\frac{\\partial w}{\\partial y}$, among others. In addition to the central difference scheme, there are other ways to algorithmically approximate a discrete derivative such as forward difference and backwards difference. As this project matures, more methods will become available for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_cen_diff(f,dxy):\n",
    "    \"\"\"\n",
    "    Takes in dxy\n",
    "    \"\"\"\n",
    "    func = f.copy()\n",
    "    diff = np.zeros_like(func)\n",
    "    diff[1:-1, 1:-1] = (func[1:-1, 2:] - func[1:-1, :-2]) / (2*dxy)\n",
    "    return diff\n",
    "\n",
    "def y_cen_diff(f,dxy):\n",
    "    \"\"\"\n",
    "    Takes in dxy\n",
    "    \"\"\"\n",
    "    func = f.copy()\n",
    "    diff = np.zeros_like(func)\n",
    "    diff[1:-1, 1:-1] = (func[:-2, 1:-1]-func[2:, 1:-1]) / (2*dxy)\n",
    "    return diff\n",
    "\n",
    "# and a quick funtion to make our lives easier and calculate all spatial derivative at the same time\n",
    "def calculate_spatial_derivatives(vars, dxy):\n",
    "    \"\"\"\n",
    "    Takes in dxy\n",
    "    \"\"\"\n",
    "    if len(vars) == 1:\n",
    "        differentiated_x = x_cen_diff(vars[0],dxy)\n",
    "        differentiated_y = y_cen_diff(vars[0],dxy)\n",
    "        return differentiated_x, differentiated_y\n",
    "    elif len(vars) == 2:\n",
    "        arrays = []\n",
    "        for dim in vars:\n",
    "            differentiated_x = x_cen_diff(dim, dxy)\n",
    "            differentiated_y = y_cen_diff(dim, dxy)\n",
    "            arrays.append(differentiated_x)\n",
    "            arrays.append(differentiated_y)\n",
    "        return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb7fab",
   "metadata": {},
   "source": [
    "Along with functions to calculate the central difference derivative, we will also need a function to calculate the laplacian operator $\\nabla^2$.\n",
    "\n",
    "The discrete approximation is:  \n",
    "  \n",
    "$\\nabla^2 f \\approx \\frac{f_{i, j-1} + f_{i-1, j} - 4f_{i, j} + f_{i, j+1} + f_{i+1, j}}{\\text{element length}^2}$  \n",
    "  \n",
    "The use of the laplacian operator is shown in the equations in part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_laplacian(f, dxy):\n",
    "    \"\"\"\n",
    "    Takes in dxy\n",
    "    \"\"\"\n",
    "    diff = np.zeros_like(f)\n",
    "    a = f[1:-1, :-2].copy() # i , j-1\n",
    "    b = f[2:, 1:-1].copy() # i-1 , j\n",
    "    c = f[1:-1, 1:-1].copy() # i , j\n",
    "    d = f[1:-1, 2:].copy() # i , j+1\n",
    "    e = f[:-2, 1:-1].copy() # i+1 , j\n",
    "    core = (a + b - 4 * c + d + e) / (dxy**2)\n",
    "    diff[1:-1,1:-1] = core\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d75cbd",
   "metadata": {},
   "source": [
    "#### Compute tentative velocities ($u^{*}$, $w^{*}$)\n",
    "Now we need a function designed to advect the fluid parcel on a pixel by pixel basis using the derivatives and the velocities at this current time step. As discussed above, we ignore the pressure, so we call these velocities *tentative*. Later we will calculate the pressure gradient by solving the pressure Poisson equation and correct our tentative velocities to what they should be, therefore abiding by the incompressibility criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907a88f",
   "metadata": {},
   "source": [
    "Now we will build a function to advect the velocities from $t_n$ to their tentative velocities at $t_{n+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advect(u_prev, w_prev, dt, Kviscosity, du_dx, du_dy, dw_dx, dw_dy, lapl_u, lapl_w):\n",
    "    \"\"\"\n",
    "    Takes in u, v, dt, Kviscosity, du_dx, du_dy, dw_dx, dw_dy, laplace_u, laplace_w\n",
    "    \"\"\"\n",
    "    u_tent = (u_prev + (dt * (-1*(u_prev * du_dx + w_prev * du_dy) + Kviscosity * lapl_u)))\n",
    "    w_tent = (w_prev + (dt * (-1*(u_prev * dw_dx + w_prev * dw_dy) + Kviscosity * lapl_w)))\n",
    "\n",
    "    return u_tent, w_tent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7fb932",
   "metadata": {},
   "source": [
    "After the fluid has been advected with the `advect` function, it still is not satisfying the second equation in the Navier-Stokes system of partial differential equations. There is still the *incompressibility condition*, $\\nabla \\cdot U = 0$, which needs to be solved. This is done through the Pressure Poisson Equation, which we will now construct a function to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24998e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ppe(p_prev, du_dx, dw_dy, dxy, dt, density, poisson_iterations):\n",
    "    \"\"\"\n",
    "    Takes in dxy, dt, density, poisson_iterations\n",
    "    \"\"\"\n",
    "\n",
    "    rhs = (density / dt * (du_dx + dw_dy)) # right-hand-side\n",
    "\n",
    "    for _ in range(poisson_iterations):\n",
    "        p_next = np.zeros_like(p_prev)\n",
    "\n",
    "        p_next[1:-1, 1:-1] = 1/4 * (p_prev[1:-1, 0:-2] + p_prev[2:, 1:-1] + p_prev[1:-1, 2:  ] + p_prev[:-2, 1:-1] - dxy**2 * rhs[1:-1, 1:-1])\n",
    "\n",
    "        # Homogeneous Dirichlet boundary condition at the top\n",
    "\n",
    "        # Pressure Boundary Conditions: Homogeneous Neumann Boundary\n",
    "        # conditions everywhere except for the top, where it is a \n",
    "        # homogeneous Dirichlet BC\n",
    "        p_next[:,  0] = p_next[:,  1] # LEFT\n",
    "        p_next[:, -1] = p_next[:, -2] # RIGHT\n",
    "        p_next[-1,  :] = p_next[-2,  :] # BOTTOM\n",
    "        p_next[0, :] = 0.0 # TOP\n",
    "\n",
    "        p_prev = p_next\n",
    "    \n",
    "    return p_next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66d8d5",
   "metadata": {},
   "source": [
    "After the pressure poisson equation is solved, the derivative of the pressure field can be calculated and, from that, the tentative velocity field is corrected to the true velocities at $t_{n+1}$, the following function `enforce_incompressibility` takes in the pressure derivatives from the Pressure Poisson equation and outputs the corrected velocities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3696072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_incompressibility(velocities, dp, dt, density):\n",
    "    \"\"\"\n",
    "    Inputs: list of velocity fields of form [u, w], list of pressure derivative fields of form [dp_dx, dp_dy]\n",
    "\n",
    "    Ouputs: list of corrected velocity fields of form [u_corrected, w_corrected] which can be unpacked via direct\n",
    "    assignment\n",
    "\n",
    "    Takes in dt, densit\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = []\n",
    "    for vel, dp_i in zip(velocities, dp):\n",
    "        vel_next = (vel - dt / density * dp_i)\n",
    "        arrays.append(vel_next)\n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ea8e2",
   "metadata": {},
   "source": [
    "#### A quick note on numerical stability\n",
    "The stability of a simulation is of great importance. In the time integration of the Navier-Stokes equations on a discrete grid, information can travel \"too fast\" depending on the chosen $\\Delta t$, $\\Delta x$, and $\\nu$. In order to avoid this, or at least catch it when it occurs so we know how to update our configuration, the Courant-Friedrichs-Lewy condition for stability is used iteratively at each pixel for each time integration. If a pixel is identified as failing the condition, an Error is raised and the program stops running. Additionally, to better visualize how error propogates and to get a better intuitive understanding of the algorithmic basis of this model, the CFL value for each pixel at each time step will be recorded, and made available for further data analysis and plotting. The Courant-Friedrichs-Lewy condition for stability is expressed as so:\n",
    "\n",
    "- $C=\\frac{\\Delta t}{\\Delta x}u+\\frac{\\Delta t}{\\Delta y}w\\leq C_{max}$\n",
    "  \n",
    "- where $C_{max}$ is typically 1 for explicit schemes, but this number can be experimented with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CFL(CFL_condition, u, w, dxy, dt):\n",
    "    \"\"\"\n",
    "    This function checks whether the velocity field is meeting the Courant-Friedrichs-Lewy condition for stability\n",
    "\n",
    "    Takes in dxy, dt\n",
    "    \"\"\"\n",
    "    C = ((dt/dxy)*u)+((dt/dxy)*w)\n",
    "    C_max = np.max(C)\n",
    "\n",
    "    check = C_max <= CFL_condition\n",
    "\n",
    "    return C, C_max, check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfa45f",
   "metadata": {},
   "source": [
    "### Time Integration\n",
    "The following function puts all the steps together into a time-stepping scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(ics, bcs, domain_size, Nx, dt, Ndt, density, Kviscosity, poisson_iterations, CFL_condition, plot):\n",
    "    \"\"\"\n",
    "    ics, bcs, domain_size, Nx, dt, density, Kviscosity, poisson_iterations, CFL_condition, plot (bool)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create XArray DataArray for dependent variables u, w, p\n",
    "    coords = {'xdim':np.linspace(0.0,domain_size,Nx),'ydim':np.linspace(0.0,domain_size,Nx),'tdim':np.arange(0.0,Ndt,dt)}\n",
    "    uxarr, wxarr, pxarr = create_arrays(coords, ics, bcs)\n",
    "\n",
    "    # Create XArray DataArray for Vorticity and CFL Data\n",
    "    cxarr = xr.DataArray(np.zeros_like(uxarr.data[:,:,:]), dims=list([key for key in coords.keys()]), coords=coords)\n",
    "    vxarr = xr.DataArray(np.zeros_like(uxarr.data[:,:,:]), dims=list([key for key in coords.keys()]), coords=coords)\n",
    "\n",
    "    n_iterations = len(coords['tdim'])\n",
    "    dxy = domain_size / (Nx-1)\n",
    "\n",
    "    for t in tqdm(range(n_iterations-1)):\n",
    "\n",
    "        # Pre-emptive step: extract data from XArray DataArray for current time-step\n",
    "        if t == 0:\n",
    "            u = uxarr.data[:,:,t].copy()\n",
    "            w = wxarr.data[:,:,t].copy()\n",
    "            p = pxarr.data[:,:,t].copy()\n",
    "        \n",
    "        # Step 1: calculate spatial derivatives and laplacian for u and w\n",
    "        du_dx = x_cen_diff(u, dxy=dxy)\n",
    "        du_dy = y_cen_diff(u, dxy=dxy)\n",
    "        dw_dx = x_cen_diff(w, dxy=dxy)\n",
    "        dw_dy = y_cen_diff(w, dxy=dxy)\n",
    "        laplace_u = calculate_laplacian(u,dxy=dxy)\n",
    "        laplace_w = calculate_laplacian(w,dxy=dxy)\n",
    "\n",
    "        # Step 2: advect velocities to tentative velocities at tn+1, ignoring pressure term\n",
    "        u_tent, w_tent = advect(u_prev=u, w_prev=w, dt=dt, Kviscosity=Kviscosity, du_dx=du_dx, du_dy=du_dy,\n",
    "                                dw_dx=dw_dx, dw_dy=dw_dy, lapl_u=laplace_u, lapl_w=laplace_w)\n",
    "\n",
    "        # Step 3: Enforce boundary conditions on tentative velocities\n",
    "        u_tent_bc, w_tent_bc = enforce_bc(bcs, u_tent, w_tent)\n",
    "\n",
    "        # Step 4: calculate spatial derivatives for tentative u and w\n",
    "        du_tent_dx = x_cen_diff(u_tent_bc, dxy=dxy)\n",
    "        dw_tent_dy = y_cen_diff(w_tent_bc, dxy=dxy)\n",
    "\n",
    "        # Step 5: Solve Pressure Poisson Equation (PPE), solving pressure boundary conditions at each iteration\n",
    "        p_final = solve_ppe(p, du_tent_dx, dw_tent_dy, dxy=dxy,dt=dt, density=density, poisson_iterations=poisson_iterations)\n",
    "        \n",
    "        # Step 6: Calculate spatial derivatives for pressure field\n",
    "        dp_dx = x_cen_diff(p_final, dxy=dxy)\n",
    "        dp_dy = y_cen_diff(p_final, dxy=dxy)\n",
    "\n",
    "        # Step 7: Enforce compressibility with solved PPE\n",
    "        u_enforced, w_enforced = enforce_incompressibility([u_tent_bc, w_tent_bc],[dp_dx, dp_dy], dt=dt, density=density)\n",
    "\n",
    "        # Step 8: Enforce boundary conditions on corrected velocities\n",
    "        u_final, w_final = enforce_bc(bcs, u_enforced, w_enforced)\n",
    "\n",
    "        # Step 9: Check admissability with CFL condition:\n",
    "        C_field, cmax, check = CFL(CFL_condition, u_final, w_final, dxy=dxy, dt=dt)\n",
    "        \n",
    "        # Step 10: Calculate vorticity\n",
    "        vorticity = x_cen_diff(w_final, dxy=dxy) - y_cen_diff(u_final, dxy=dxy)\n",
    "        \n",
    "        if check:\n",
    "            uxarr.data[:,:,t+1] = u_final\n",
    "            wxarr.data[:,:,t+1] = w_final\n",
    "            pxarr.data[:,:,t+1] = p_final\n",
    "            vxarr.data[:,:,t+1] = vorticity\n",
    "            cxarr.data[:,:,t+1] = C_field\n",
    "            u = u_final\n",
    "            w = w_final\n",
    "            p = p_final\n",
    "        else:\n",
    "            if plot:\n",
    "                plt.figure(1, figsize=(30,10))\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.pcolormesh(C_field)\n",
    "                plt.colorbar()\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.title('Courant-Friedrichs-Lewy condition values')\n",
    "                plt.xlabel('$j$')\n",
    "                plt.ylabel('$i$')\n",
    "                plt.subplot(1,2,2)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.pcolormesh(p_final)\n",
    "                plt.colorbar()\n",
    "                plt.quiver(u_final,w_final)\n",
    "                plt.title('Colormesh of Pressure and Quiver plot of velocity')\n",
    "                plt.xlabel('$j$')\n",
    "                plt.ylabel('$i$')\n",
    "                \n",
    "            print(f'Courant-Friedrichs-Lewy condition failed at time t={t}, C={cmax}')\n",
    "            return uxarr, wxarr, pxarr, vxarr, cxarr\n",
    "    return uxarr, wxarr, pxarr, vxarr, cxarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851bc737",
   "metadata": {},
   "source": [
    "Now we have successfully created a function to run the entire simulation from start to finish. The cell below initialize the variables we will plug into the model, which were discussed at length at the beginning of section 2. The current settings are:\n",
    "- initial conditions: zero everywhere\n",
    "- boundary conditions: no-slip everywhere except the top which is prescribed (u=1,w=0)\n",
    "- domain size: 1\n",
    "- number of spatial grid points(x and y): 64\n",
    "- time step: 0.001\n",
    "- total time (seconds): 10\n",
    "- Kinematic viscosity: 0.1\n",
    "- density: 1.0\n",
    "- iterations of Pressure Poisson solver: 50\n",
    "- Courant-Friedrichs-Lewy maximum condition: 1\n",
    "\n",
    "These model setting are fairly arbitrary, and in later sections we will explore how changing these paramters can change the model output. For now lets run it has it is and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell first . . .\n",
    "model_type = 'navier_stokes'\n",
    "domain_size = 1\n",
    "Nx = 100\n",
    "dt = 0.00001\n",
    "Ndt = 0.05\n",
    "ics = ((ufunc_x,ufunc_y),(wfunc_x,wfunc_y),(pfunc_x,pfunc_y))\n",
    "bcs = ((0,0),(0,0),(1,0),(0,0))\n",
    "Kviscosity = 0.0005\n",
    "forcings = None\n",
    "density = 1.0\n",
    "poisson_iterations = 50\n",
    "CFL_condition = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . . Then this cell second\n",
    "uxarr, wxarr, pxarr, vxarr, cxarr = sim(ics=ics,\n",
    "    bcs=bcs,\n",
    "    domain_size=domain_size,\n",
    "    Nx=Nx,\n",
    "    dt=dt,\n",
    "    Ndt=Ndt,\n",
    "    density=density,\n",
    "    Kviscosity=Kviscosity,\n",
    "    poisson_iterations=poisson_iterations,\n",
    "    CFL_condition=CFL_condition, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca14e44",
   "metadata": {},
   "source": [
    "Running the above code should have resulted in a failure of the simulation, with a print statement saying \"*Courant-Friedrichs-Lewy condition failed at time t=123, C=1.22*\". A more blown up version of the right plot is shown below, it is a colorplot showing the pressure gradient with a quiverplot overlain showing the velocity. Obviously something is very wrong here as indicated by the incredibly high pressure values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(vxarr.data[:,:,-1])\n",
    "plt.colorbar()\n",
    "plt.quiver(uxarr.data[:,:,-1],wxarr.data[:,:,-1])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('$j$')\n",
    "plt.ylabel('$i$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45af97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data3(index):\n",
    "    data = vxarr.data[:,:,index]\n",
    "    # bounds=(0, 0, 10, 10)\n",
    "    return hv.Image(data).opts(\n",
    "        colorbar=True,\n",
    "        cmap='Viridis',\n",
    "        clim=(data.min(), data.max()),\n",
    "        width=400,\n",
    "        height=400,\n",
    "        tools=['hover']\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "dmap3 = hv.DynamicMap(plot_data3, kdims=[hv.Dimension('Time Step (Index)', values=np.arange(1,Ndt/dt, dtype=int))])\n",
    "pn.Column(\"# Plot of vorticity as a function of time\", dmap3).servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243792a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae114a2",
   "metadata": {},
   "source": [
    "## 4. Results and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b5ec2",
   "metadata": {},
   "source": [
    "Using `holoviews` and the ability of the `sim()` function to be put in a loop while iterating over configurations, we are able to look at the effect of changing parameters in a really accessible way. In the below cell, the values of `Nx` are iterated over, starting at 10 and increasing by 10 until 100 (this runs 10 iterations of `sim()`). As a reminder, `Nx` represents the number of grid points along each axis of the mesh, and it follows that the number of grid cells is $Nx^2$ within a equally spaced square mesh. `Nx` is a natural parameter to test first due to the inherent relationship between the Courant-Friedrichs-Lewy number and the grid spacing. Run the cell below to generate the data required to plot with `holoviews`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383d2b9",
   "metadata": {},
   "source": [
    "### The effect of grid spacing on number of iterations to failure and CFL plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a27bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx_list = np.arange(10,110,10, dtype=int)\n",
    "cfl_data_list = []\n",
    "C_field_list = []\n",
    "\n",
    "for Nx1 in Nx_list:\n",
    "    uxarr, wxarr, pxarr, cfl_data, C_field = sim(ics=ics,\n",
    "                                        bcs=bcs,\n",
    "                                        domain_size=domain_size,\n",
    "                                        Nx=Nx1,\n",
    "                                        dt=dt,\n",
    "                                        Ndt=Ndt,\n",
    "                                        density=density,\n",
    "                                        Kviscosity=Kviscosity,\n",
    "                                        poisson_iterations=poisson_iterations,\n",
    "                                        CFL_condition=CFL_condition,\n",
    "                                        plot=False)\n",
    "    cfl_data_list.append(cfl_data)\n",
    "    C_field_list.append(C_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab75ad",
   "metadata": {},
   "source": [
    "The below cell defines a plot function with `holoviews` and inserts it into the `DynamicMap` class to create an interactive colorplot of the CFL values at failure for 10 different values of `Nx`. The values of `Nx` are by index position, and the real value of `Nx` can be easily calculated with: $10(Nx+1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab90a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(index):\n",
    "    data = C_field_list[index]\n",
    "    return hv.Image(data, bounds=(0, 0, 10, 10)).opts(\n",
    "        colorbar=True,\n",
    "        cmap='Viridis',\n",
    "        clim=(data.min(), data.max()),\n",
    "        width=400,\n",
    "        height=400,\n",
    "        tools=['hover']\n",
    "    )\n",
    "\n",
    "dmap = hv.DynamicMap(plot_data, kdims=[hv.Dimension('Nx', values=list(range(len(C_field_list))))])\n",
    "pn.Column(\"# Plot of CFL values at failure based on number of grid points (Nx)\", dmap).servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8771d",
   "metadata": {},
   "source": [
    "### The effect of Domain Size on number of iterations to failure and CFL plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8553aa6",
   "metadata": {},
   "source": [
    "Now lets set `Nx` to constant and change the `domain_size` parameter to see if that changes the output any more than `Nx` does. Changing `domain_size` will allow us to keep the same grid resolution while simultaneously changing the $\\Delta x$ and $\\Delta y$ parameters. It is equivalent to changing the coordinate distance between each point on the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_size_list = [410,610,810,1010,1210,1410,1610,1810,2010,2210]\n",
    "cfl_data_list = []\n",
    "C_field_list = []\n",
    "\n",
    "for domain_size_i in domain_size_list:\n",
    "    uxarr, wxarr, pxarr, cfl_data, C_field = sim(ics=ics,\n",
    "                                        bcs=bcs,\n",
    "                                        domain_size=domain_size_i,\n",
    "                                        Nx=41,\n",
    "                                        dt=dt,\n",
    "                                        Ndt=Ndt,\n",
    "                                        density=density,\n",
    "                                        Kviscosity=Kviscosity,\n",
    "                                        poisson_iterations=poisson_iterations,\n",
    "                                        CFL_condition=CFL_condition,\n",
    "                                        plot=False)\n",
    "    cfl_data_list.append(cfl_data)\n",
    "    C_field_list.append(C_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data2(index):\n",
    "    data = C_field_list[index]\n",
    "    return hv.Image(data, bounds=(0, 0, 10, 10)).opts(\n",
    "        colorbar=True,\n",
    "        cmap='Viridis',\n",
    "        clim=(data.min(), data.max()),\n",
    "        width=400,\n",
    "        height=400,\n",
    "        tools=['hover']\n",
    "    )\n",
    "\n",
    "dmap2 = hv.DynamicMap(plot_data, kdims=[hv.Dimension('Domain Size', values=list(range(71)))])\n",
    "pn.Column(\"# Plot of CFL values at failure based on total length of coordinate axis (Domain Size)\", dmap2).servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff8158",
   "metadata": {},
   "source": [
    "## 5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75895a45",
   "metadata": {},
   "source": [
    "The simulations did not result in stable numerical solutions to the Navier-Stokes equations in this configuration. As indicated by calculating the Courant-Friedrichs-Lewy condition for stability across the grid, and then plotting the resulting colormap for iterations at failure across a few different configurations, the simulation was only stable for a limited amount of time (anywhere between 50-250 iterations) before the derivatives of the vector field blew up. This is an unfortunate outcome, but understanding can still be gleamed from what we have.  \n",
    "  \n",
    "Interestingly, as we increased the number of grid points (effectively decreasing $\\Delta x$ and $\\Delta y$), we can note a few things that are different from when we increased the total spatial span of the grid (effectively increading $\\Delta x$ and $\\Delta y$). Firsly, when we increased the number of grid points (`Nx`), it was possible to see from the print statement that the time to failure was decreasing by almost a third as much, whereas when we increased the total spatial span of the grid the time to failure increased. This does make sense in the context of the CFL equation presented earlier:  \n",
    "  \n",
    "$C=\\frac{\\Delta t}{\\Delta x}u+\\frac{\\Delta t}{\\Delta y}w\\leq C_{max}$\n",
    "  \n",
    "When the spatial dimension is *decreased* (as is the case with increasing grid resolution for the same spatial span), we are increasing the $\\frac{\\Delta t}{\\Delta (x,y)}$ term because the spatial step is in the demoninator, effectively decreasing the maximum velocity that can be achieved before breaking the condition. This is why we see a decrease in the time to failure when we increase grid resolution. And vice-versa for *increasing* the spatial dimension via increasing the total spatial span (leaving grid resolution constant).  \n",
    "  \n",
    "Finally, we can see from the interactive color plots created with `holoviews` that when we increase the spatial span, there is no noticeable change in the location of the CFL value anomolies within the mesh, whereas this is starkly opposed to what we observe when we change the mesh resolution by changing `Nx`. As we increase the grid resolution, the CFL anomolies move closer and closer to top-right hand corner of the grid. This makes intuitive sense as this is where velocitiy and pressure would \"pile up\" as the fluid is advected to the right during each time integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0a24f",
   "metadata": {},
   "source": [
    "### A note on limitations and future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9954d76",
   "metadata": {},
   "source": [
    "As mentioned in the discussion, it is unfortunate that the simulation is not stable beyond a few hundred iterations, but from the data that we were able to generate we learned a few things that will help create more robust models in the future. Namely, becuase of the fact that the CFL anomoly values seemed to be clustered in the top right hand corner of the mesh, it seems that the cause of error may come from an incorrect implementation of the Pressure Poisson. This is my guess to the cause of error mainly becuase when I've run this simulation in a framework that is stable, large amounts of pressure build in that corner, and it is reasonable to assume that if the pressure gradient was not handled well, error could propogate very quickly.\n",
    "  \n",
    "As mentioned in the introduction, this notebook will be one in a series of running attempts to generalize toy fluid dynamics models for the purpose of hands-on, self-directed, intuitive learning of topics in Geophysical Fluid Dynamics. To that end, additional capabilities are in the works to be added, including the ability to perform data-driven science and engineering workflows to the data generated by these models. Modal decompositions, for example, could be an interesting way to represent a toy model of flow past a cylindar and would help encapsulate the dynamics of vortex shedding (one of many phenomenon which could be observed), and which has direct applications to GFD. PySINDy is another module that I would like to also incorporate in the future, developed by Brunton et al. [2] PySINDy is the Python implementation of SINDy (Sparse Identification of Nonlinear Dynamics), an algorithm that has been shown to be able to identify the sparse terms associated with systems like incompressible Navier-Stokes and the Lorenz system of ODEs from data alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c531834",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d17a83",
   "metadata": {},
   "source": [
    "1. Durran, D. R. . (1999). Numerical methods for wave equations in geophysical fluid dynamics. Springer International Publishing. \n",
    "  \n",
    "2. S.L. Brunton, J.L. Proctor, & J.N. Kutz, Discovering governing equations from data by sparse identification of nonlinear dynamical systems, Proc. Natl. Acad. Sci. U.S.A. 113 (15) 3932-3937, https://doi.org/10.1073/pnas.1517384113 (2016)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cavity-flow-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
